{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24cc9da9-ebb2-438c-8da8-34a73b16e4d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# FaceMask Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e990bc1-3fd6-4785-936a-d5e633553eb4",
   "metadata": {},
   "source": [
    "`Group Name: Gogogo`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1755c7b7-e9dc-4aba-a9e9-145127d0ceac",
   "metadata": {},
   "source": [
    "\n",
    "|     Name      | Student ID |\n",
    "| :-----------: | :--------: |\n",
    "|  Puquan Chen  |  z5405329  |\n",
    "| Wenzhen Zhang |  z5282188  |\n",
    "|   Zeran Qiu   |  z5237346  |\n",
    "| Xiaolan Zhang |  z5400028  |\n",
    "|  Haoyu Zang   |  z5326339  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da956912-10aa-46b7-91fa-909b7d0f5074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3c167d3-1290-449a-be41-e5726dce16a1",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2c305c-db80-414e-944d-356e29879ac8",
   "metadata": {},
   "source": [
    "## 1.1 Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14b85cc-4338-462f-9a9b-bf255c93853b",
   "metadata": {},
   "source": [
    "COVID-19 has been going on for three years. Although its impact is waning in many areas, we still do not have a good solution to the harm it causes to humans. Therefore the use of facial masks has significantly increased on many occasions. Nevertheless, it is still important to develop social awareness of residents to wear facial masks, since it is common to find people in narrow public spaces without masks. In this case, we need face mask detection to help local authorities better monitor people's compliance with local mask wearing policies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b36fc0-71fc-4eff-8ef7-1db832135a87",
   "metadata": {},
   "source": [
    "## 1.2 Motivation\n",
    "As mentioned above, in a climate where COVID-19 is still spreading, we need to ensure that people comply with the mask wearing policy. However, it is very difficult to identify whether people are wearing a mask by human intervention alone, especially in crowded situations such as trains and shopping malls. Therefore, there is a great need for face mask detection to help us quickly and accurately identify whether people are wearing masks or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5b35c9-d621-4775-91b2-c4ea5fbbadfb",
   "metadata": {},
   "source": [
    "## 1.3 Purpose/ Project Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b3a69e-2768-43d0-9d93-77675a6af80f",
   "metadata": {},
   "source": [
    "\n",
    "In this project, our group applied three existing popular deep learning object detection models which includes `RCNN`, `YOLO` and `SSD`, aim to compare their performance in accuracy, training time and loss rate by using the same data set. Aftering getting all necessary data and details, our group will build our own model based on the existing models mentioned in above and try to analysis the methods which can be used and improve the performance of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3844475-7d00-4afe-8416-a1f5e47ac501",
   "metadata": {},
   "source": [
    "# 2. Data Sources / Preparation of Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7685d080-4022-4398-84de-2d07bbd7a186",
   "metadata": {},
   "source": [
    "**All scripts used in this part are stored in the directory** `./tool_scripts` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62cb077-1ff1-4e64-a62f-5a0f08bc51f2",
   "metadata": {},
   "source": [
    "## 2.1 Basic Information about The Data \n",
    "\n",
    "Our original face mask dataset contains 6120 images, it comes from https://github.com/AIZOOTech/FaceMaskDetection\n",
    "\n",
    "Nevertheless, the Face Mask Dataset is a combined dataset, the training set made up of 3114 images of Wider Face and 3006 images of masking FAces (MAFA) datasets. It contains normal faces with different lighting, poses, occlusion, and masked face.The test set has 1839 images which includes 780 Wider Face and 1059 MAFA dataset. Here are some samples of original images include in dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266dba74-fa12-4802-ab01-8245ceb11018",
   "metadata": {},
   "outputs": [],
   "source": [
    "!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32ace4-f605-4e0c-8084-6ac4a5b7a00e",
   "metadata": {},
   "source": [
    "Since some format of label files in original dataset are not readable, the pre-processing has been applied to the original dataset. The images in available formats were identified and some invalid dataset was deleted. However, after processing and editing, the number of reliable images reduced dramatically which could affect the following training, our group collected and added extra images to ensure the amount and quality of the whole dataset. Extra datasets refers to the link below:\n",
    "1. https://public.roboflow.com/object-detection/mask-wearing\n",
    "2. https://www.kaggle.com/datasets/andrewmvd/face-mask-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cbfecb-4352-4280-af32-24a1ac70f01c",
   "metadata": {},
   "source": [
    "## 2.2 Split Dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66033d95-2645-4d19-90da-1277c6797f2c",
   "metadata": {},
   "source": [
    "After integrating three datasets, we try to split the whole datasets into training set, validation set and testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221497b-cc70-4787-b527-5d023cce5501",
   "metadata": {},
   "source": [
    "We used [split_dataset.py](./tool_scripts/split_dataset.py) to do the spliting task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c038db-5e74-40f9-b987-8cda5a38af70",
   "metadata": {},
   "source": [
    "The script can be run on dataset with the command below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d9081b-cc37-46e8-a6e6-241f5ccb2bd7",
   "metadata": {},
   "source": [
    "`python3 split_dataset.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc64c1-2def-441d-ab82-f14259fca502",
   "metadata": {},
   "source": [
    "Our final face mask dataset contains `18756` training images, `2993` validation images and `2993` testing images "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ec5e0b-30c9-4778-818e-603547987d1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.3 Process Dataset Labels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e12ac7c-9ef6-4ab6-b2ba-10851e1fa660",
   "metadata": {},
   "source": [
    "We tried to train our models based on different frameworks, we used `yolov5` for yolo and `mmdetection` for others, but they need different format of labels, such as `xml`, `txt`, and `json`. Therefore, we created and ran scripts that those label files can be interchangeable\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beaf857-e820-4781-ac9c-5cc47c27f770",
   "metadata": {},
   "source": [
    "The usage of those scripts:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c033c564-8dc6-415b-931a-3faecb326d94",
   "metadata": {},
   "source": [
    "- 1. [formatting_xml.py](./tool_scripts): reformat the `xml` files so that it can be processed by other scripts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2938ca-c42b-4c0c-9a6c-a34338b0a171",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" width = \"650\" height = \"300\" src=\"./notebook_images/2.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a223e7c9-3e87-466a-ad62-66ba9befda31",
   "metadata": {},
   "source": [
    "- 2. [xml_to_txt.py](./tool_scripts/xml_to_txt.py): convert `xml` format labels to `txt` format labels. The `txt` format is also called yolo format, which only contains the information about object class, object coordinates, height, and width as the image shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f92f3-20bd-4ef0-9927-cab0521afd6b",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" width = \"650\" height = \"300\" src=\"./notebook_images/3.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70756f56-c48b-4e88-ad4c-ac985eaa7dd1",
   "metadata": {},
   "source": [
    "- 3. [txt_to_xml.py](./tool_scripts/txt_to_xml.py): convert `txt` format labels to `xml` format labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807cf088-2a6a-46d8-b303-97f00ebc2779",
   "metadata": {},
   "source": [
    "Code reference of this part can be found in [tool_scripts/README.md](./tool_scripts/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb146e9-1143-4215-abe0-ad7e0d97d57a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5920f3f9-c0ec-4a25-b2e5-60c6d4ebf150",
   "metadata": {},
   "source": [
    "## 3.1 RCNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a511534-87a0-48fd-b09d-3fb48fe72ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc59a234-014c-4d86-8d3c-4084367c0c4f",
   "metadata": {},
   "source": [
    "## 3.2 SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509a720c-7276-406e-978d-210f46228c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8b4a138-c6aa-4c07-a528-996f9115943f",
   "metadata": {},
   "source": [
    "## 3.3 Yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18537a6-2245-4fec-9e98-290cbcf7063c",
   "metadata": {},
   "source": [
    "#### Model Architecture / Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041aa155-be96-4d1d-a5e6-db0148c9a080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a86d8dc4-0e31-45f8-9e33-5187c2d165bd",
   "metadata": {},
   "source": [
    "#### Hyper Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a6853e-e748-4782-a36e-86f69abf55a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e2a10f0-ee64-4865-8910-93971c5f2da9",
   "metadata": {},
   "source": [
    "#### Experiment Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb27cf6-db31-4666-abf7-493d47e53c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f30ec4aa-d468-4efc-b65c-b201271a5d06",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Install environment\n",
    "1. `cd yolov5`\n",
    "2. `conda create -n yolov5 python=3.8`\n",
    "3. `conda activate yolov5`\n",
    "4. `pip install -r requirements.txt`\n",
    "5. `jupyter lab`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d6f40-88a2-4ba9-99e1-f4c9018f2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65c5193-9246-4580-9d6a-9a0a045a26c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8585c07-de87-4886-a3c2-40319e02abf2",
   "metadata": {},
   "source": [
    "#### Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e6877-735d-4c18-a82e-5e146674f295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb2649e-f713-4586-a844-fec9582c0ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79cad4f-3b85-4a3a-a72a-bd5cc941c7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d3859dd-5897-440d-b1bc-5c27c6878a4d",
   "metadata": {},
   "source": [
    "# 4. Comparision/ Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a78141-2fcc-493b-8516-841ff32801f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
